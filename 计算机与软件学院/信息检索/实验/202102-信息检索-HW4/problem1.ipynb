{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import heapq\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [vae, variational, autoencoder, for, heterogen...\n",
      "1     [fr-fmss, federated, recommendation, via, fake...\n",
      "2     [transfer, learning, in, collaborative, recomm...\n",
      "3     [mitigating, confounding, bias, in, recommenda...\n",
      "4     [fedrec, lossless, federated, recommendation, ...\n",
      "                            ...                        \n",
      "75    [fedrec, federated, recommendation, with, expl...\n",
      "76    [cofi-points, collaborative, filtering, via, p...\n",
      "77    [transfer, learning, from, app, domain, to, ne...\n",
      "78    [toccf, time-aware, one-class, collaborative, ...\n",
      "79    [rbpr, role-based, bayesian, personalized, ran...\n",
      "Length: 80, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 打开文件\n",
    "f = open('HW4_1.txt')\n",
    "# 读取文章，并删除每行结尾的换行符\n",
    "docs = pd.Series(f.read().splitlines())\n",
    "\n",
    "# 打开文件\n",
    "f = open('HW4_1.txt')\n",
    "# 读取文章，并删除每行结尾的换行符\n",
    "sentences = pd.Series(f.read().splitlines())\n",
    "\n",
    "# 转换为小写，并使用正则表达式进行切割\n",
    "docs = docs.apply(lambda x: re.split('[^a-zA-Z-]', x.lower()))\n",
    "# 删除空串\n",
    "for line in docs:\n",
    "    while '' in line:\n",
    "        line.remove('')\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.67264107\n",
      " 0.         0.32330639 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.45593196 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.42596873 0.         0.         0.\n",
      " 0.         0.         0.         0.         1.42596873 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.20411998 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.60205999 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.90308999 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.12493874 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         1.90308999\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.34678749 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         1.90308999 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 1.90308999 0.         0.         1.90308999 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.75696195 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         1.90308999\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.05799195 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.32330639 0.         0.         0.         0.\n",
      " 0.         0.         0.60205999 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.34678749 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         1.60205999 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.20411998 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.44069199 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.94884748 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.60205999 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.34678749 0.\n",
      " 1.90308999 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         1.90308999 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.90308999 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.75696195 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.94884748 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         1.90308999 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.60205999 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/alex_shen/SynologyDrive/PcBackup/深圳大学/课程/大三下/信息检索/实验/202102-信息检索-HW4/problem1.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alex_shen/SynologyDrive/PcBackup/%E6%B7%B1%E5%9C%B3%E5%A4%A7%E5%AD%A6/%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E4%B8%89%E4%B8%8B/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/%E5%AE%9E%E9%AA%8C/202102-%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2-HW4/problem1.ipynb#ch0000002?line=19'>20</a>\u001b[0m \u001b[39m# 计算tf-idf\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alex_shen/SynologyDrive/PcBackup/%E6%B7%B1%E5%9C%B3%E5%A4%A7%E5%AD%A6/%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E4%B8%89%E4%B8%8B/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/%E5%AE%9E%E9%AA%8C/202102-%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2-HW4/problem1.ipynb#ch0000002?line=20'>21</a>\u001b[0m tf_idf[i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(tf, idf)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alex_shen/SynologyDrive/PcBackup/%E6%B7%B1%E5%9C%B3%E5%A4%A7%E5%AD%A6/%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E4%B8%89%E4%B8%8B/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/%E5%AE%9E%E9%AA%8C/202102-%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2-HW4/problem1.ipynb#ch0000002?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39;49m(tf_idf[i])\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/ipykernel/iostream.py:529\u001b[0m, in \u001b[0;36mOutStream.write\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    527\u001b[0m is_child \u001b[39m=\u001b[39m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_master_process())\n\u001b[1;32m    528\u001b[0m \u001b[39m# only touch the buffer in the IO thread to avoid races\u001b[39;00m\n\u001b[0;32m--> 529\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpub_thread\u001b[39m.\u001b[39;49mschedule(\u001b[39mlambda\u001b[39;49;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mwrite(string))\n\u001b[1;32m    530\u001b[0m \u001b[39mif\u001b[39;00m is_child:\n\u001b[1;32m    531\u001b[0m     \u001b[39m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[39;00m\n\u001b[1;32m    532\u001b[0m     \u001b[39m# and this helps.\u001b[39;00m\n\u001b[1;32m    533\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_subprocess_flush_pending:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/ipykernel/iostream.py:214\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_events\u001b[39m.\u001b[39mappend(f)\n\u001b[1;32m    213\u001b[0m     \u001b[39m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_pipe\u001b[39m.\u001b[39;49msend(\u001b[39mb\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    215\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     f()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/zmq/sugar/socket.py:618\u001b[0m, in \u001b[0;36mSocket.send\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    611\u001b[0m         data \u001b[39m=\u001b[39m zmq\u001b[39m.\u001b[39mFrame(\n\u001b[1;32m    612\u001b[0m             data,\n\u001b[1;32m    613\u001b[0m             track\u001b[39m=\u001b[39mtrack,\n\u001b[1;32m    614\u001b[0m             copy\u001b[39m=\u001b[39mcopy \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    615\u001b[0m             copy_threshold\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_threshold,\n\u001b[1;32m    616\u001b[0m         )\n\u001b[1;32m    617\u001b[0m     data\u001b[39m.\u001b[39mgroup \u001b[39m=\u001b[39m group\n\u001b[0;32m--> 618\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(data, flags\u001b[39m=\u001b[39;49mflags, copy\u001b[39m=\u001b[39;49mcopy, track\u001b[39m=\u001b[39;49mtrack)\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:740\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:787\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:244\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/zmq/backend/cython/checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 统计文档集字典，加入set去重\n",
    "term_set = set()\n",
    "for line in docs:\n",
    "    term_set.update(set(line))\n",
    "\n",
    "# 统计df，即每个词项在文档集中的出现次数（每个文档中只记一次）\n",
    "idf = [0 for i in range(len(term_set))]\n",
    "for i, word in enumerate(term_set):\n",
    "    df = list(word in line for line in docs).count(True)\n",
    "    idf[i] = math.log(len(docs) / df, 10)\n",
    "    \n",
    "# 计算tf-idf\n",
    "tf_idf = [[] for i in range(len(docs))]\n",
    "for i in range(len(docs)):\n",
    "    index, doc = i, docs[i]\n",
    "    \n",
    "    # 统计每个词项在每条文档中的出现次数。\n",
    "    tf = [0 if doc.count(term) == 0 else 1 + math.log(doc.count(term), 10) for term in term_set]\n",
    "    \n",
    "    # 计算tf-idf\n",
    "    tf_idf[i] = np.multiply(tf, idf)\n",
    "    print(tf_idf[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第1相似:\n",
      "文档1和文档74的相似度为0.57\n",
      "文档1的内容为VAE++: Variational AutoEncoder for Heterogeneous One-Class Collaborative Filtering\n",
      "文档74的内容为Staged Variational AutoEncoder for Heterogeneous One-Class Collaborative\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第2相似:\n",
      "文档1和文档60的相似度为0.3\n",
      "文档1的内容为VAE++: Variational AutoEncoder for Heterogeneous One-Class Collaborative Filtering\n",
      "文档60的内容为Transfer Learning for Heterogeneous One-Class Collaborative Filtering\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第3相似:\n",
      "文档1和文档73的相似度为0.26\n",
      "文档1的内容为VAE++: Variational AutoEncoder for Heterogeneous One-Class Collaborative Filtering\n",
      "文档73的内容为Tri-task Variational Autoencoder for Modeling of Biased and Unbiased Unary Feedback in Recommender Systems\n",
      "====================================================================================================\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第1相似:\n",
      "文档2和文档76的相似度为0.12\n",
      "文档2的内容为FR-FMSS: Federated Recommendation via Fake Marks and Secret Sharing\n",
      "文档76的内容为FedRec: Federated Recommendation with Explicit Feedback via User Averaging\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第2相似:\n",
      "文档2和文档38的相似度为0.12\n",
      "文档2的内容为FR-FMSS: Federated Recommendation via Fake Marks and Secret Sharing\n",
      "文档38的内容为FedRec: Federated Recommendation with Explicit Feedback\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第3相似:\n",
      "文档2和文档5的相似度为0.1\n",
      "文档2的内容为FR-FMSS: Federated Recommendation via Fake Marks and Secret Sharing\n",
      "文档5的内容为FedRec++: Lossless Federated Recommendation with Explicit Feedback\n",
      "====================================================================================================\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第1相似:\n",
      "文档3和文档32的相似度为0.56\n",
      "文档3的内容为Transfer Learning in Collaborative Recommendation for Bias Reduction\n",
      "文档32的内容为Transfer Learning in Collaborative Filtering for Sparsity Reduction\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第2相似:\n",
      "文档3和文档4的相似度为0.32\n",
      "文档3的内容为Transfer Learning in Collaborative Recommendation for Bias Reduction\n",
      "文档4的内容为Mitigating Confounding Bias in Recommendation via Information Bottleneck\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第3相似:\n",
      "文档3和文档68的相似度为0.25\n",
      "文档3的内容为Transfer Learning in Collaborative Recommendation for Bias Reduction\n",
      "文档68的内容为Transfer Learning in Heterogeneous Collaborative Filtering Domains\n",
      "====================================================================================================\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第1相似:\n",
      "文档4和文档3的相似度为0.32\n",
      "文档4的内容为Mitigating Confounding Bias in Recommendation via Information Bottleneck\n",
      "文档3的内容为Transfer Learning in Collaborative Recommendation for Bias Reduction\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第2相似:\n",
      "文档4和文档68的相似度为0.09\n",
      "文档4的内容为Mitigating Confounding Bias in Recommendation via Information Bottleneck\n",
      "文档68的内容为Transfer Learning in Heterogeneous Collaborative Filtering Domains\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第3相似:\n",
      "文档4和文档32的相似度为0.07\n",
      "文档4的内容为Mitigating Confounding Bias in Recommendation via Information Bottleneck\n",
      "文档32的内容为Transfer Learning in Collaborative Filtering for Sparsity Reduction\n",
      "====================================================================================================\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第1相似:\n",
      "文档5和文档38的相似度为0.79\n",
      "文档5的内容为FedRec++: Lossless Federated Recommendation with Explicit Feedback\n",
      "文档38的内容为FedRec: Federated Recommendation with Explicit Feedback\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第2相似:\n",
      "文档5和文档76的相似度为0.57\n",
      "文档5的内容为FedRec++: Lossless Federated Recommendation with Explicit Feedback\n",
      "文档76的内容为FedRec: Federated Recommendation with Explicit Feedback via User Averaging\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第3相似:\n",
      "文档5和文档61的相似度为0.25\n",
      "文档5的内容为FedRec++: Lossless Federated Recommendation with Explicit Feedback\n",
      "文档61的内容为Mixed Factorization for Collaborative Recommendation with Heterogeneous Explicit Feedbacks\n",
      "====================================================================================================\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第1相似:\n",
      "文档6和文档14的相似度为0.5\n",
      "文档6的内容为Asymmetric Pairwise Preference Learning for Heterogeneous One-Class Collaborative Filtering\n",
      "文档14的内容为Asymmetric Bayesian Personalized Ranking for One-Class Collaborative Filtering\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第2相似:\n",
      "文档6和文档60的相似度为0.41\n",
      "文档6的内容为Asymmetric Pairwise Preference Learning for Heterogeneous One-Class Collaborative Filtering\n",
      "文档60的内容为Transfer Learning for Heterogeneous One-Class Collaborative Filtering\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第3相似:\n",
      "文档6和文档22的相似度为0.39\n",
      "文档6的内容为Asymmetric Pairwise Preference Learning for Heterogeneous One-Class Collaborative Filtering\n",
      "文档22的内容为Adaptive Pairwise Preference Learning for Collaborative Recommendation with Implicit Feedbacks\n",
      "====================================================================================================\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第1相似:\n",
      "文档7和文档49的相似度为0.21\n",
      "文档7的内容为FISSA: Fusing Item Similarity Models with Self-Attention Networks for Sequential Recommendation\n",
      "文档49的内容为Next-Item Recommendation via Collaborative Filtering with Bidirectional Item Similarity\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第2相似:\n",
      "文档7和文档37的相似度为0.19\n",
      "文档7的内容为FISSA: Fusing Item Similarity Models with Self-Attention Networks for Sequential Recommendation\n",
      "文档37的内容为TransRec++: Translation-based Sequential Recommendation with Heterogeneous Feedback\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第3相似:\n",
      "文档7和文档16的相似度为0.17\n",
      "文档7的内容为FISSA: Fusing Item Similarity Models with Self-Attention Networks for Sequential Recommendation\n",
      "文档16的内容为BIS: Bidirectional Item Similarity for Next-Item Recommendation\n",
      "====================================================================================================\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第1相似:\n",
      "文档8和文档63的相似度为0.19\n",
      "文档8的内容为A General Knowledge Distillation Framework for Counterfactual Recommendation via Uniform Data\n",
      "文档63的内容为Compressed Knowledge Transfer via Factorization Machine for Heterogeneous Collaborative Recommendation\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第2相似:\n",
      "文档8和文档62的相似度为0.14\n",
      "文档8的内容为A General Knowledge Distillation Framework for Counterfactual Recommendation via Uniform Data\n",
      "文档62的内容为A Survey of Transfer Learning for Collaborative Recommendation with Auxiliary Data Extended from part of my Ph.D. thesis.\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第3相似:\n",
      "文档8和文档43的相似度为0.11\n",
      "文档8的内容为A General Knowledge Distillation Framework for Counterfactual Recommendation via Uniform Data\n",
      "文档43的内容为A Survey on Heterogeneous One-Class Collaborative Filtering\n",
      "====================================================================================================\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第1相似:\n",
      "文档9和文档60的相似度为0.71\n",
      "文档9的内容为Adaptive Transfer Learning for Heterogeneous One-Class Collaborative Filtering\n",
      "文档60的内容为Transfer Learning for Heterogeneous One-Class Collaborative Filtering\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第2相似:\n",
      "文档9和文档22的相似度为0.39\n",
      "文档9的内容为Adaptive Transfer Learning for Heterogeneous One-Class Collaborative Filtering\n",
      "文档22的内容为Adaptive Pairwise Preference Learning for Collaborative Recommendation with Implicit Feedbacks\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第3相似:\n",
      "文档9和文档64的相似度为0.38\n",
      "文档9的内容为Adaptive Transfer Learning for Heterogeneous One-Class Collaborative Filtering\n",
      "文档64的内容为Adaptive Bayesian Personalized Ranking for Heterogeneous Implicit Feedbacks\n",
      "====================================================================================================\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第1相似:\n",
      "文档10和文档60的相似度为0.24\n",
      "文档10的内容为PAT: Preference-Aware Transfer Learning for Recommendation with Heterogeneous Feedback\n",
      "文档60的内容为Transfer Learning for Heterogeneous One-Class Collaborative Filtering\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第2相似:\n",
      "文档10和文档65的相似度为0.24\n",
      "文档10的内容为PAT: Preference-Aware Transfer Learning for Recommendation with Heterogeneous Feedback\n",
      "文档65的内容为Interaction-Rich Transfer Learning for Collaborative Filtering with Heterogeneous User Feedback\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "第3相似:\n",
      "文档10和文档57的相似度为0.19\n",
      "文档10的内容为PAT: Preference-Aware Transfer Learning for Recommendation with Heterogeneous Feedback\n",
      "文档57的内容为Mixed Similarity Learning for Recommendation with Implicit Feedback\n"
     ]
    }
   ],
   "source": [
    "# 计算文档间两两的余弦相似度\n",
    "cosine_similaritys = [[] for i in range(len(docs))]\n",
    "for i in range(len(docs)):\n",
    "    for j in range(len(docs)):\n",
    "        index1, index2 = i+1, j+1\n",
    "        doc1, doc2 = sentences[i], sentences[j]\n",
    "\n",
    "        # 取出两个文档的tf-idf向量\n",
    "        v1 = tf_idf[i]\n",
    "        v2 = tf_idf[j]\n",
    "\n",
    "        # 计算余弦相似度\n",
    "        cos = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "        cosine_similaritys[i].append([cos, index1, index2, doc1, doc2])\n",
    "\n",
    "for cosine_similarity in cosine_similaritys:\n",
    "    cosine_similarity.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "for cosine_similarity in cosine_similaritys[:10]:\n",
    "    print('====================================================================================================')\n",
    "    for i in range(1, 4):\n",
    "        print('---------------------------------------------------------------------------------------------------------------------------------------')\n",
    "        print('第{}相似:'.format(i))\n",
    "        print('文档{}和文档{}的相似度为{}'.format(cosine_similarity[i][1], cosine_similarity[i][2], round(cosine_similarity[i][0], 2)))\n",
    "        print('文档{}的内容为{}'.format(cosine_similarity[i][1], cosine_similarity[i][3]))\n",
    "        print('文档{}的内容为{}'.format(cosine_similarity[i][2], cosine_similarity[i][4]))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b38f256b5e5cfcb08c8fab1bb2c0ed1d264b1b0baf1af9aa926f047321c09a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
