{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Adaptive Pairwise Preference Learning for Coll...\n",
      "1     HGMF: Hierarchical Group Matrix Factorization ...\n",
      "2     Adaptive Bayesian Personalized Ranking for Het...\n",
      "3     Compressed Knowledge Transfer via Factorizatio...\n",
      "4     A Survey of Transfer Learning for Collaborativ...\n",
      "5     Mixed Factorization for Collaborative Recommen...\n",
      "6     Transfer Learning for Heterogeneous One-Class ...\n",
      "7     Group Bayesian Personalized Ranking with Rich ...\n",
      "8     Transfer Learning for Semi-Supervised Collabor...\n",
      "9             Transfer Learning for Behavior Prediction\n",
      "10    TOCCF: Time-Aware One-Class Collaborative Filt...\n",
      "11    RBPR: Role-based Bayesian Personalized Ranking...\n",
      "12    Hybrid One-Class Collaborative Filtering for J...\n",
      "13    Mixed Similarity Learning for Recommendation w...\n",
      "14    Collaborative Recommendation with Multiclass P...\n",
      "15               Transfer Learning for Behavior Ranking\n",
      "16    Transfer Learning from APP Domain to News Doma...\n",
      "17    k-CoFi: Modeling k-Granularity Preference Cont...\n",
      "18    CoFi-points: Collaborative Filtering via Point...\n",
      "19    Personalized Recommendation with Implicit Feed...\n",
      "20    BIS: Bidirectional Item Similarity for Next-It...\n",
      "21    RLT: Residual-Loop Training in Collaborative F...\n",
      "22    MF-DMPC: Matrix Factorization with Dual Multic...\n",
      "23    Transfer to Rank for Heterogeneous One-Class C...\n",
      "24    Neighborhood-Enhanced Transfer Learning for On...\n",
      "25    Next-Item Recommendation via Collaborative Fil...\n",
      "26    Asymmetric Bayesian Personalized Ranking for O...\n",
      "27                  Context-aware Collaborative Ranking\n",
      "28            Transfer to Rank for Top-N Recommendation\n",
      "29    Dual Similarity Learning for Heterogeneous One...\n",
      "30    Sequence-Aware Factored Mixed Similarity Model...\n",
      "31    PAT: Preference-Aware Transfer Learning for Re...\n",
      "32    Adaptive Transfer Learning for Heterogeneous O...\n",
      "33    A General Knowledge Distillation Framework for...\n",
      "34    FISSA: Fusing Item Similarity Models with Self...\n",
      "35    Asymmetric Pairwise Preference Learning for He...\n",
      "36    k-Reciprocal Nearest Neighbors Algorithm for O...\n",
      "37    CoFiGAN: Collaborative Filtering by Generative...\n",
      "38    Conditional Restricted Boltzmann Machine for I...\n",
      "39    Matrix Factorization with Heterogeneous Multic...\n",
      "40    CoFi-points: Collaborative Filtering via Point...\n",
      "41    A Survey on Heterogeneous One-Class Collaborat...\n",
      "42    Holistic Transfer to Rank for Top-N Recommenda...\n",
      "43    FedRec: Federated Recommendation with Explicit...\n",
      "44    Factored Heterogeneous Similarity Model for Re...\n",
      "45    FCMF: Federated Collective Matrix Factorizatio...\n",
      "46    Sequence-Aware Similarity Learning for Next-It...\n",
      "47    FR-FMSS: Federated Recommendation via Fake Mar...\n",
      "48    Transfer Learning in Collaborative Recommendat...\n",
      "49    Mitigating Confounding Bias in Recommendation ...\n",
      "50    FedRec++: Lossless Federated Recommendation wi...\n",
      "51    VAE++: Variational AutoEncoder for Heterogeneo...\n",
      "52    TransRec++: Translation-based Sequential Recom...\n",
      "53    Collaborative filtering with implicit feedback...\n",
      "54    Interaction-Rich Transfer Learning for Collabo...\n",
      "55    Transfer Learning in Heterogeneous Collaborati...\n",
      "56    GBPR: Group Preference based Bayesian Personal...\n",
      "57    CoFiSet: Collaborative Filtering via Learning ...\n",
      "58    Modeling Item Category for Effective Recommend...\n",
      "59    Position-Aware Context Attention for Session-B...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 打开文件\n",
    "f = open('HW1.txt')\n",
    "# 读取文章，并删除每行结尾的换行符\n",
    "doc = pd.Series(f.read().splitlines())\n",
    "\n",
    "print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [adaptive, pairwise, preference, learning, for...\n",
      "1     [hgmf, hierarchical, group, matrix, factorizat...\n",
      "2     [adaptive, bayesian, personalized, ranking, fo...\n",
      "3     [compressed, knowledge, transfer, via, factori...\n",
      "4     [a, survey, of, transfer, learning, for, colla...\n",
      "5     [mixed, factorization, for, collaborative, rec...\n",
      "6     [transfer, learning, for, heterogeneous, one, ...\n",
      "7     [group, bayesian, personalized, ranking, with,...\n",
      "8     [transfer, learning, for, semi, supervised, co...\n",
      "9       [transfer, learning, for, behavior, prediction]\n",
      "10    [toccf, time, aware, one, class, collaborative...\n",
      "11    [rbpr, role, based, bayesian, personalized, ra...\n",
      "12    [hybrid, one, class, collaborative, filtering,...\n",
      "13    [mixed, similarity, learning, for, recommendat...\n",
      "14    [collaborative, recommendation, with, multicla...\n",
      "15         [transfer, learning, for, behavior, ranking]\n",
      "16    [transfer, learning, from, app, domain, to, ne...\n",
      "17    [k, cofi, modeling, k, granularity, preference...\n",
      "18    [cofi, points, collaborative, filtering, via, ...\n",
      "19    [personalized, recommendation, with, implicit,...\n",
      "20    [bis, bidirectional, item, similarity, for, ne...\n",
      "21    [rlt, residual, loop, training, in, collaborat...\n",
      "22    [mf, dmpc, matrix, factorization, with, dual, ...\n",
      "23    [transfer, to, rank, for, heterogeneous, one, ...\n",
      "24    [neighborhood, enhanced, transfer, learning, f...\n",
      "25    [next, item, recommendation, via, collaborativ...\n",
      "26    [asymmetric, bayesian, personalized, ranking, ...\n",
      "27             [context, aware, collaborative, ranking]\n",
      "28    [transfer, to, rank, for, top, n, recommendation]\n",
      "29    [dual, similarity, learning, for, heterogeneou...\n",
      "30    [sequence, aware, factored, mixed, similarity,...\n",
      "31    [pat, preference, aware, transfer, learning, f...\n",
      "32    [adaptive, transfer, learning, for, heterogene...\n",
      "33    [a, general, knowledge, distillation, framewor...\n",
      "34    [fissa, fusing, item, similarity, models, with...\n",
      "35    [asymmetric, pairwise, preference, learning, f...\n",
      "36    [k, reciprocal, nearest, neighbors, algorithm,...\n",
      "37    [cofigan, collaborative, filtering, by, genera...\n",
      "38    [conditional, restricted, boltzmann, machine, ...\n",
      "39    [matrix, factorization, with, heterogeneous, m...\n",
      "40    [cofi, points, collaborative, filtering, via, ...\n",
      "41    [a, survey, on, heterogeneous, one, class, col...\n",
      "42    [holistic, transfer, to, rank, for, top, n, re...\n",
      "43    [fedrec, federated, recommendation, with, expl...\n",
      "44    [factored, heterogeneous, similarity, model, f...\n",
      "45    [fcmf, federated, collective, matrix, factoriz...\n",
      "46    [sequence, aware, similarity, learning, for, n...\n",
      "47    [fr, fmss, federated, recommendation, via, fak...\n",
      "48    [transfer, learning, in, collaborative, recomm...\n",
      "49    [mitigating, confounding, bias, in, recommenda...\n",
      "50    [fedrec, lossless, federated, recommendation, ...\n",
      "51    [vae, variational, autoencoder, for, heterogen...\n",
      "52    [transrec, translation, based, sequential, rec...\n",
      "53    [collaborative, filtering, with, implicit, fee...\n",
      "54    [interaction, rich, transfer, learning, for, c...\n",
      "55    [transfer, learning, in, heterogeneous, collab...\n",
      "56    [gbpr, group, preference, based, bayesian, per...\n",
      "57    [cofiset, collaborative, filtering, via, learn...\n",
      "58    [modeling, item, category, for, effective, rec...\n",
      "59    [position, aware, context, attention, for, ses...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 转换为小写，并使用正则表达式进行切割\n",
    "doc = doc.apply(lambda x: re.split('[^a-zA-Z]', x.lower()))\n",
    "# 删除空串\n",
    "for list in doc:\n",
    "    while '' in list:\n",
    "        list.remove('')\n",
    "print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'for': [42, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 45, 46, 47, 49, 52, 55, 57, 59, 60], 'collaborative': [35, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 18, 19, 22, 24, 25, 26, 27, 28, 30, 33, 36, 37, 38, 41, 42, 46, 49, 52, 54, 55, 56, 57, 58], 'recommendation': [31, 1, 2, 4, 5, 6, 9, 13, 14, 15, 17, 20, 21, 26, 29, 31, 32, 34, 35, 38, 39, 43, 44, 45, 47, 48, 49, 50, 51, 53, 59, 60], 'filtering': [26, 7, 8, 11, 12, 13, 18, 19, 22, 24, 25, 26, 27, 30, 33, 36, 37, 38, 41, 42, 46, 52, 54, 55, 56, 57, 58], 'learning': [22, 1, 5, 7, 9, 10, 14, 16, 17, 19, 20, 25, 30, 32, 33, 36, 41, 47, 49, 54, 55, 56, 58], 'with': [18, 1, 5, 6, 8, 14, 15, 20, 23, 26, 32, 35, 40, 44, 45, 51, 53, 54, 55], 'heterogeneous': [18, 3, 4, 6, 7, 12, 24, 30, 32, 33, 36, 40, 42, 45, 46, 52, 53, 55, 56], 'transfer': [16, 4, 5, 7, 9, 10, 16, 17, 24, 25, 29, 32, 33, 43, 49, 55, 56], 'one': [16, 7, 8, 11, 12, 13, 24, 25, 27, 30, 33, 36, 37, 38, 42, 52, 57], 'class': [16, 7, 8, 11, 12, 13, 24, 25, 27, 30, 33, 36, 37, 38, 42, 52, 57], 'item': [14, 19, 20, 21, 21, 26, 26, 31, 35, 39, 41, 47, 54, 58, 59], 'via': [10, 4, 19, 20, 26, 34, 41, 48, 50, 54, 58], 'preference': [10, 1, 15, 18, 19, 23, 32, 36, 40, 41, 57], 'feedback': [9, 14, 20, 32, 44, 45, 51, 53, 54, 55], 'similarity': [8, 14, 21, 26, 30, 31, 35, 45, 47], 'ranking': [7, 3, 8, 12, 16, 27, 28, 57], 'factorization': [7, 2, 4, 6, 22, 23, 40, 46], 'personalized': [6, 3, 8, 12, 20, 27, 57], 'implicit': [6, 1, 3, 14, 20, 45, 54], 'context': [6, 15, 18, 23, 28, 40, 60], 'aware': [6, 11, 28, 31, 32, 47, 60], 'pairwise': [5, 1, 20, 36, 54, 58], 'in': [5, 18, 22, 49, 50, 56], 'bayesian': [5, 3, 8, 12, 27, 57], 'to': [4, 17, 24, 29, 43], 'sets': [4, 19, 20, 54, 58], 'over': [4, 19, 20, 54, 58], 'next': [4, 21, 26, 31, 47], 'matrix': [4, 2, 23, 40, 46], 'federated': [4, 44, 46, 48, 51], 'based': [4, 12, 53, 57, 60], 'and': [4, 22, 38, 48, 54], 'user': [3, 41, 54, 55], 'rank': [3, 24, 29, 43], 'preferences': [3, 20, 54, 58], 'multiclass': [3, 15, 23, 40], 'mixed': [3, 6, 14, 31], 'k': [3, 18, 18, 37], 'group': [3, 2, 8, 57], 'feedbacks': [3, 1, 3, 6], 'explicit': [3, 6, 44, 51], 'dual': [3, 17, 23, 30], 'cofi': [3, 18, 19, 41], 'adaptive': [3, 1, 3, 33], 'a': [3, 5, 34, 42], 'training': [2, 22, 38], 'top': [2, 29, 43], 'survey': [2, 5, 42], 'sequential': [2, 35, 53], 'sequence': [2, 31, 47], 'rich': [2, 8, 55], 'prediction': [2, 10, 23], 'pointwise': [2, 19, 41], 'points': [2, 19, 41], 'on': [2, 41, 42], 'neighborhood': [2, 22, 25], 'n': [2, 29, 43], 'modeling': [2, 18, 59], 'model': [2, 31, 45], 'machine': [2, 4, 39], 'knowledge': [2, 4, 34], 'fedrec': [2, 44, 51], 'factored': [2, 31, 45], 'domain': [2, 17, 17], 'data': [2, 5, 34], 'bidirectional': [2, 21, 26], 'bias': [2, 49, 50], 'behavior': [2, 10, 16], 'attention': [2, 35, 60], 'asymmetric': [2, 27, 36], 'variational': [1, 52], 'vae': [1, 52], 'uniform': [1, 34], 'transrec': [1, 53], 'translation': [1, 53], 'toccf': [1, 11], 'time': [1, 11], 'supervised': [1, 9], 'start': [1, 17], 'sharing': [1, 48], 'set': [1, 41], 'session': [1, 60], 'semi': [1, 9], 'self': [1, 35], 'secret': [1, 48], 'role': [1, 12], 'rlt': [1, 22], 'restricted': [1, 39], 'residual': [1, 22], 'reduction': [1, 49], 'reciprocal': [1, 37], 'rbpr': [1, 12], 'rating': [1, 23], 'position': [1, 60], 'pat': [1, 32], 'of': [1, 5], 'news': [1, 17], 'networks': [1, 35], 'neighbors': [1, 37], 'nearest': [1, 37], 'models': [1, 35], 'mitigating': [1, 50], 'mf': [1, 23], 'marks': [1, 48], 'lossless': [1, 51], 'loop': [1, 22], 'local': [1, 22], 'job': [1, 13], 'interactions': [1, 8], 'interaction': [1, 55], 'information': [1, 50], 'hybrid': [1, 13], 'holistic': [1, 43], 'hierarchical': [1, 2], 'hgmf': [1, 2], 'groups': [1, 54], 'granularity': [1, 18], 'global': [1, 22], 'generative': [1, 38], 'general': [1, 34], 'gbpr': [1, 57], 'fusing': [1, 35], 'from': [1, 17], 'framework': [1, 34], 'fr': [1, 48], 'fmss': [1, 48], 'fissa': [1, 35], 'fcmf': [1, 46], 'fake': [1, 48], 'enhanced': [1, 25], 'effective': [1, 59], 'domains': [1, 56], 'dmpc': [1, 23], 'distillation': [1, 34], 'discriminative': [1, 38], 'counterfactual': [1, 34], 'confounding': [1, 50], 'conditional': [1, 39], 'compressed': [1, 4], 'combining': [1, 22], 'collective': [1, 46], 'cold': [1, 17], 'cofiset': [1, 58], 'cofigan': [1, 38], 'category': [1, 59], 'by': [1, 38], 'bottleneck': [1, 50], 'boltzmann': [1, 39], 'bis': [1, 21], 'auxiliary': [1, 5], 'autoencoder': [1, 52], 'app': [1, 17], 'algorithm': [1, 37]}\n"
     ]
    }
   ],
   "source": [
    "hashtable = {}\n",
    "for index, list in enumerate(doc):\n",
    "    for word in list:\n",
    "        if word in hashtable:\n",
    "            hashtable[word].append(index+1)\n",
    "            hashtable[word][0] += 1\n",
    "        else:\n",
    "            hashtable[word] = [1, index+1]\n",
    "hashtable = dict(\n",
    "    sorted(hashtable.items(), key=lambda kv: (kv[1][0], kv[0]), reverse=True))\n",
    "\n",
    "print(hashtable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>doc.freq</th>\n",
       "      <th>postings list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for</td>\n",
       "      <td>42</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collaborative</td>\n",
       "      <td>35</td>\n",
       "      <td>[1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 18, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recommendation</td>\n",
       "      <td>31</td>\n",
       "      <td>[1, 2, 4, 5, 6, 9, 13, 14, 15, 17, 20, 21, 26,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filtering</td>\n",
       "      <td>26</td>\n",
       "      <td>[7, 8, 11, 12, 13, 18, 19, 22, 24, 25, 26, 27,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>learning</td>\n",
       "      <td>22</td>\n",
       "      <td>[1, 5, 7, 9, 10, 14, 16, 17, 19, 20, 25, 30, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>with</td>\n",
       "      <td>18</td>\n",
       "      <td>[1, 5, 6, 8, 14, 15, 20, 23, 26, 32, 35, 40, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>heterogeneous</td>\n",
       "      <td>18</td>\n",
       "      <td>[3, 4, 6, 7, 12, 24, 30, 32, 33, 36, 40, 42, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>transfer</td>\n",
       "      <td>16</td>\n",
       "      <td>[4, 5, 7, 9, 10, 16, 17, 24, 25, 29, 32, 33, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>one</td>\n",
       "      <td>16</td>\n",
       "      <td>[7, 8, 11, 12, 13, 24, 25, 27, 30, 33, 36, 37,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>class</td>\n",
       "      <td>16</td>\n",
       "      <td>[7, 8, 11, 12, 13, 24, 25, 27, 30, 33, 36, 37,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>item</td>\n",
       "      <td>14</td>\n",
       "      <td>[19, 20, 21, 21, 26, 26, 31, 35, 39, 41, 47, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>via</td>\n",
       "      <td>10</td>\n",
       "      <td>[4, 19, 20, 26, 34, 41, 48, 50, 54, 58]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>preference</td>\n",
       "      <td>10</td>\n",
       "      <td>[1, 15, 18, 19, 23, 32, 36, 40, 41, 57]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feedback</td>\n",
       "      <td>9</td>\n",
       "      <td>[14, 20, 32, 44, 45, 51, 53, 54, 55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>similarity</td>\n",
       "      <td>8</td>\n",
       "      <td>[14, 21, 26, 30, 31, 35, 45, 47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ranking</td>\n",
       "      <td>7</td>\n",
       "      <td>[3, 8, 12, 16, 27, 28, 57]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>factorization</td>\n",
       "      <td>7</td>\n",
       "      <td>[2, 4, 6, 22, 23, 40, 46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>personalized</td>\n",
       "      <td>6</td>\n",
       "      <td>[3, 8, 12, 20, 27, 57]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>implicit</td>\n",
       "      <td>6</td>\n",
       "      <td>[1, 3, 14, 20, 45, 54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>context</td>\n",
       "      <td>6</td>\n",
       "      <td>[15, 18, 23, 28, 40, 60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              term doc.freq                                      postings list\n",
       "0              for       42  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16...\n",
       "1    collaborative       35  [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 18, 1...\n",
       "2   recommendation       31  [1, 2, 4, 5, 6, 9, 13, 14, 15, 17, 20, 21, 26,...\n",
       "3        filtering       26  [7, 8, 11, 12, 13, 18, 19, 22, 24, 25, 26, 27,...\n",
       "4         learning       22  [1, 5, 7, 9, 10, 14, 16, 17, 19, 20, 25, 30, 3...\n",
       "5             with       18  [1, 5, 6, 8, 14, 15, 20, 23, 26, 32, 35, 40, 4...\n",
       "6    heterogeneous       18  [3, 4, 6, 7, 12, 24, 30, 32, 33, 36, 40, 42, 4...\n",
       "7         transfer       16  [4, 5, 7, 9, 10, 16, 17, 24, 25, 29, 32, 33, 4...\n",
       "8              one       16  [7, 8, 11, 12, 13, 24, 25, 27, 30, 33, 36, 37,...\n",
       "9            class       16  [7, 8, 11, 12, 13, 24, 25, 27, 30, 33, 36, 37,...\n",
       "10            item       14  [19, 20, 21, 21, 26, 26, 31, 35, 39, 41, 47, 5...\n",
       "11             via       10            [4, 19, 20, 26, 34, 41, 48, 50, 54, 58]\n",
       "12      preference       10            [1, 15, 18, 19, 23, 32, 36, 40, 41, 57]\n",
       "13        feedback        9               [14, 20, 32, 44, 45, 51, 53, 54, 55]\n",
       "14      similarity        8                   [14, 21, 26, 30, 31, 35, 45, 47]\n",
       "15         ranking        7                         [3, 8, 12, 16, 27, 28, 57]\n",
       "16   factorization        7                          [2, 4, 6, 22, 23, 40, 46]\n",
       "17    personalized        6                             [3, 8, 12, 20, 27, 57]\n",
       "18        implicit        6                             [1, 3, 14, 20, 45, 54]\n",
       "19         context        6                           [15, 18, 23, 28, 40, 60]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inverted_index = pd.DataFrame(columns=['term', 'doc.freq', 'postings list'])\n",
    "for term in hashtable:\n",
    "    inverted_index = inverted_index.append(\n",
    "        {'term': term, 'doc.freq': hashtable[term][0], 'postings list': hashtable[term][1:]}, ignore_index=True)\n",
    "display(inverted_index[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getList(word):\n",
    "    return hashtable[word][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def And(list1, list2):\n",
    "    i, j = 0, 0\n",
    "    res = []\n",
    "    while i < len(list1) and j < len(list2):\n",
    "        # 同时出现，加入结果列表\n",
    "        if list1[i] == list2[j]:\n",
    "            res.append(list1[i])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        # 指向较小数的指针后移\n",
    "        elif list1[i] < list2[j]:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Or(list1, list2):\n",
    "    i, j = 0, 0\n",
    "    res = []\n",
    "    while i < len(list1) and j < len(list2):\n",
    "        # 同时出现，只需要加入一次\n",
    "        if list1[i] == list2[j]:\n",
    "            res.append(list1[i])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        # 指向较小数的指针后移，并加入列表\n",
    "        elif list1[i] < list2[j]:\n",
    "            res.append(list1[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            res.append(list2[j])\n",
    "            j += 1\n",
    "    # 加入未遍历到的index\n",
    "    res.extend(list1[i:]) if j == len(list2) else res.extend(list2[j:])\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AndNot(list1, list2):\n",
    "    i, j = 0, 0\n",
    "    res = []\n",
    "    while i < len(list1) and j < len(list2):\n",
    "        # index相等时，同时后移\n",
    "        if list1[i] == list2[j]:\n",
    "            i += 1\n",
    "            j += 1\n",
    "        # 指向list1的index较小时，加入结果列表\n",
    "        elif list1[i] < list2[j]:\n",
    "            res.append(list1[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "    # list1 未遍历完，加入剩余index\n",
    "    if i != len(list1):\n",
    "        res.extend(list1[i:])\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transfer AND learning: [5, 7, 9, 10, 16, 17, 25, 32, 33, 49, 55, 56] \n",
      "\n",
      "transfer: [4, 5, 7, 9, 10, 16, 17, 24, 25, 29, 32, 33, 43, 49, 55, 56]\n",
      "learning: [1, 5, 7, 9, 10, 14, 16, 17, 19, 20, 25, 30, 32, 33, 36, 41, 47, 49, 54, 55, 56, 58]\n"
     ]
    }
   ],
   "source": [
    "print('transfer AND learning:', And(getList('transfer'), getList('learning')),'\\n')\n",
    "\n",
    "print('transfer:', getList('transfer'))\n",
    "print('learning:',getList('learning'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transfer AND learning AND filtering: [7, 25, 33, 55, 56] \n",
      "\n",
      "transfer: [4, 5, 7, 9, 10, 16, 17, 24, 25, 29, 32, 33, 43, 49, 55, 56]\n",
      "learning: [1, 5, 7, 9, 10, 14, 16, 17, 19, 20, 25, 30, 32, 33, 36, 41, 47, 49, 54, 55, 56, 58]\n",
      "filtering: [7, 8, 11, 12, 13, 18, 19, 22, 24, 25, 26, 27, 30, 33, 36, 37, 38, 41, 42, 46, 52, 54, 55, 56, 57, 58]\n",
      "transfer AND learning: [5, 7, 9, 10, 16, 17, 25, 32, 33, 49, 55, 56]\n"
     ]
    }
   ],
   "source": [
    "print('transfer AND learning AND filtering:', And(And(getList('transfer'), getList('learning')), getList('filtering')), '\\n')\n",
    "\n",
    "print('transfer:', getList('transfer'))\n",
    "print('learning:', getList('learning'))\n",
    "print('filtering:', getList('filtering'))\n",
    "print('transfer AND learning:', And(getList('transfer'), getList('learning')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendation AND filtering: [13, 26, 38] \n",
      "\n",
      "recommendation: [1, 2, 4, 5, 6, 9, 13, 14, 15, 17, 20, 21, 26, 29, 31, 32, 34, 35, 38, 39, 43, 44, 45, 47, 48, 49, 50, 51, 53, 59, 60]\n",
      "filtering: [7, 8, 11, 12, 13, 18, 19, 22, 24, 25, 26, 27, 30, 33, 36, 37, 38, 41, 42, 46, 52, 54, 55, 56, 57, 58]\n"
     ]
    }
   ],
   "source": [
    "print('recommendation AND filtering:', And(getList('recommendation'), getList('filtering')), '\\n')\n",
    "\n",
    "print('recommendation:', getList('recommendation'))\n",
    "print('filtering:', getList('filtering'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendation OR filtering: [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60] \n",
      "\n",
      "recommendation: [1, 2, 4, 5, 6, 9, 13, 14, 15, 17, 20, 21, 26, 29, 31, 32, 34, 35, 38, 39, 43, 44, 45, 47, 48, 49, 50, 51, 53, 59, 60]\n",
      "filtering: [7, 8, 11, 12, 13, 18, 19, 22, 24, 25, 26, 27, 30, 33, 36, 37, 38, 41, 42, 46, 52, 54, 55, 56, 57, 58]\n"
     ]
    }
   ],
   "source": [
    "print('recommendation OR filtering:', Or(getList('recommendation'), getList('filtering')), '\\n')\n",
    "\n",
    "print('recommendation:', getList('recommendation'))\n",
    "print('filtering:', getList('filtering'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transfer AND NOT (recommendation OR filtering) [10, 16] \n",
      "\n",
      "transfer: [4, 5, 7, 9, 10, 16, 17, 24, 25, 29, 32, 33, 43, 49, 55, 56]\n",
      "recommendation: [1, 2, 4, 5, 6, 9, 13, 14, 15, 17, 20, 21, 26, 29, 31, 32, 34, 35, 38, 39, 43, 44, 45, 47, 48, 49, 50, 51, 53, 59, 60]\n",
      "filtering: [7, 8, 11, 12, 13, 18, 19, 22, 24, 25, 26, 27, 30, 33, 36, 37, 38, 41, 42, 46, 52, 54, 55, 56, 57, 58]\n",
      "recommendation OR filtering: [1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n"
     ]
    }
   ],
   "source": [
    "print('transfer AND NOT (recommendation OR filtering)', \\\n",
    "    AndNot(getList('transfer'), Or(getList('recommendation'), getList('filtering'))), '\\n')\n",
    "\n",
    "print('transfer:', getList('transfer'))\n",
    "print('recommendation:', getList('recommendation'))\n",
    "print('filtering:', getList('filtering'))\n",
    "print('recommendation OR filtering:', Or(getList('recommendation'), getList('filtering')))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b38f256b5e5cfcb08c8fab1bb2c0ed1d264b1b0baf1af9aa926f047321c09a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
