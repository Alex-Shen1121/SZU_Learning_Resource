1
00:00:01,180 --> 00:00:02,410
In the next few videos I'd
在接下来的视频中
(字幕整理：中国海洋大学 黄海广,haiguang2000@qq.com )

2
00:00:02,560 --> 00:00:04,780
like to talk about machine learning system design.
我将谈到机器学习系统的设计

3
00:00:05,780 --> 00:00:06,950
These videos will touch on
这些视频将谈及

4
00:00:07,190 --> 00:00:08,370
the main issues that you may
在设计复杂的机器学习系统时

5
00:00:08,540 --> 00:00:10,140
face when designing a
你将遇到的

6
00:00:10,220 --> 00:00:11,450
complex machine learning system,
主要问题

7
00:00:12,470 --> 00:00:13,310
and will actually try to give
同时我们会试着

8
00:00:13,490 --> 00:00:14,680
advice on how to
给出一些关于

9
00:00:14,780 --> 00:00:17,580
strategize putting together a complex machine learning system.
如何巧妙构建一个复杂的机器学习系统的建议

10
00:00:18,970 --> 00:00:20,190
In case this next set
接下来的视频

11
00:00:20,340 --> 00:00:21,390
of videos seems a little
可能看起来

12
00:00:21,530 --> 00:00:23,140
disjointed that's because these
有点不连贯

13
00:00:23,360 --> 00:00:24,340
videos will touch on a
因为这些视频会涉及

14
00:00:24,450 --> 00:00:25,800
range of the different issues that
一些你在设计机器学习系统时

15
00:00:26,150 --> 00:00:28,220
you may come across when designing complex learning systems.
可能会遇到的不同问题

16
00:00:29,600 --> 00:00:31,080
And even though the
虽然

17
00:00:31,160 --> 00:00:32,270
next set of videos may seem
下面的课程的

18
00:00:32,560 --> 00:00:34,740
somewhat less mathematical, I think
的数学性可能不是那么强

19
00:00:35,050 --> 00:00:36,180
that this material may turn
但是我认为我们将要讲到的这些东西

20
00:00:36,500 --> 00:00:38,280
out to be very useful, and
是非常有用的

21
00:00:38,400 --> 00:00:39,650
potentially huge time savers
可能在构建大型的机器学习系统时

22
00:00:40,120 --> 00:00:41,610
when you're building big machine learning systems.
节省大量的时间

23
00:00:42,890 --> 00:00:44,140
Concretely, I'd like to
具体的说

24
00:00:44,260 --> 00:00:45,710
begin with the issue of
我首先要讲的是

25
00:00:46,330 --> 00:00:47,500
prioritizing how to spend
当我们在进行机器学习时

26
00:00:47,790 --> 00:00:48,680
your time on what to work
着重要考虑什么问题

27
00:00:48,980 --> 00:00:50,330
on, and I'll begin
首先我要举一个

28
00:00:50,740 --> 00:00:52,220
with an example on spam classification.
垃圾邮件分类的例子

29
00:00:55,580 --> 00:00:57,280
Let's say you want to build a spam classifier.
假如你想建立一个垃圾邮件分类器

30
00:00:58,540 --> 00:00:59,740
Here are a couple of examples
看这些垃圾邮件与

31
00:01:00,180 --> 00:01:02,340
of obvious spam and non-spam emails.
非垃圾邮件的例子

32
00:01:03,400 --> 00:01:05,350
if the one on the left tried to sell things.
左边这封邮件想向你推销东西

33
00:01:06,270 --> 00:01:07,640
And notice how spammers
注意 这封垃圾邮件

34
00:01:08,470 --> 00:01:10,080
will deliberately misspell words,
有意的拼错一些单词 就像

35
00:01:10,540 --> 00:01:13,470
like Vincent with a 1 there, and mortgages.
"Med1cine" 中有一个1 "m0rtgage"里有个0

36
00:01:14,850 --> 00:01:16,350
And on the right as maybe
右边的邮件

37
00:01:16,560 --> 00:01:17,760
an obvious example of non-stamp
显然不是一个垃圾邮件

38
00:01:18,480 --> 00:01:20,680
email, actually email from my younger brother.
实际上这是我弟弟写给我的

39
00:01:21,710 --> 00:01:22,940
Let's say we have a labeled
假设我们已经有一些

40
00:01:23,350 --> 00:01:24,560
training set of some
加过标签的训练集

41
00:01:24,860 --> 00:01:26,130
number of spam emails and
包括标注的垃圾邮件

42
00:01:26,240 --> 00:01:28,200
some non-spam emails denoted
表示为y=1

43
00:01:28,240 --> 00:01:30,780
with labels y equals 1 or 0,
和非垃圾邮件 表示为y=0

44
00:01:31,290 --> 00:01:32,600
how do we build a
我们如何

45
00:01:33,110 --> 00:01:34,900
classifier using supervised learning
以监督学习的方法来构造一个分类器

46
00:01:35,230 --> 00:01:37,130
to distinguish between spam and non-spam?
来区分垃圾邮件和非垃圾邮件呢？

47
00:01:38,130 --> 00:01:39,670
In order to apply supervised learning,
为了应用监督学习

48
00:01:40,340 --> 00:01:41,430
the first decision we must
我们首先

49
00:01:41,660 --> 00:01:43,190
make is how do
必须确定的是

50
00:01:43,270 --> 00:01:44,860
we want to represent x, that
如何用邮件的特征

51
00:01:45,260 --> 00:01:46,590
is the features of the email.
构造向量x

52
00:01:47,430 --> 00:01:48,900
Given the features x and
给出训练集中的

53
00:01:49,160 --> 00:01:50,290
the labels y in our
特征x和标签y

54
00:01:50,410 --> 00:01:51,510
training set, we can then
我们就能够训练出某种分类器

55
00:01:51,720 --> 00:01:54,660
train a classifier, for example using logistic regression.
比如用逻辑回归的方法

56
00:01:56,150 --> 00:01:57,120
Here's one way to choose
这里有一种选择

57
00:01:57,550 --> 00:01:59,630
a set of features for our emails.
邮件的一些特征变量的方法

58
00:02:00,850 --> 00:02:01,930
We could come up with,
比如说我们可能会想出

59
00:02:02,280 --> 00:02:03,630
say, a list of maybe
一系列单词

60
00:02:03,870 --> 00:02:05,170
a hundred words that we think
或者成百上千的单词

61
00:02:05,440 --> 00:02:06,850
are indicative of whether e-mail
我们可以认为这些单词

62
00:02:07,190 --> 00:02:09,230
is spam or non-spam, for
能够用来区分垃圾邮件或非垃圾邮件

63
00:02:09,370 --> 00:02:10,410
example, if a piece of
比如说 如果有封邮件

64
00:02:10,580 --> 00:02:11,640
e-mail contains the word 'deal'
包含单词"deal(交易)"

65
00:02:12,340 --> 00:02:13,350
maybe it's more likely to be
那么它就很有可能是一封垃圾邮件

66
00:02:13,460 --> 00:02:14,410
spam if it contains
同时

67
00:02:14,850 --> 00:02:16,280
the word  'buy' maybe more
包含单词"buy(买)"的邮件

68
00:02:16,450 --> 00:02:17,670
likely to be spam, a
也很有可能是一封垃圾邮件

69
00:02:17,990 --> 00:02:19,340
word like 'discount' is more
包含"discount(折扣)"的邮件

70
00:02:19,580 --> 00:02:20,900
likely to be spam, whereas if
也很有可能是垃圾邮件

71
00:02:21,080 --> 00:02:22,340
a piece of email contains my name,
如果一封邮件中

72
00:02:23,920 --> 00:02:25,350
Andrew, maybe that means
包含了我的名字"Andrew"

73
00:02:25,630 --> 00:02:26,870
the person actually knows who
这有可能是一个知道我的人写的

74
00:02:26,910 --> 00:02:27,740
I am and that might mean it's
这说明这封邮件

75
00:02:27,900 --> 00:02:30,090
less likely to be spam.
不太可能是垃圾邮件

76
00:02:31,470 --> 00:02:32,580
And maybe for some reason I think
因为某些原因 我认为

77
00:02:32,840 --> 00:02:33,990
the word "now" may be
"now(现在)"这个单词表明了

78
00:02:34,260 --> 00:02:35,680
indicative of non-spam because
这封邮件可能并不是垃圾邮件

79
00:02:35,980 --> 00:02:37,150
I get a lot of urgent
因为我经常收到一些很紧急的邮件

80
00:02:37,540 --> 00:02:39,370
emails, and so on,
当然还有别的单词

81
00:02:39,520 --> 00:02:41,220
and maybe we choose a hundred words or so.
我们可以选出这样成百上千的单词

82
00:02:42,380 --> 00:02:43,510
Given a piece of email,
给出一封这样的邮件

83
00:02:43,970 --> 00:02:44,930
we can then take this piece
我们可以将这封邮件

84
00:02:45,180 --> 00:02:46,220
of email and encode
用一个特征向量

85
00:02:46,640 --> 00:02:47,970
it into a feature
来表示

86
00:02:48,290 --> 00:02:49,930
vector as follows.
方法如下

87
00:02:50,810 --> 00:02:51,450
I'm going to take my list of a
现在我列出一些

88
00:02:51,720 --> 00:02:54,560
hundred words and sort
之前选好的单词

89
00:02:54,960 --> 00:02:56,620
them in alphabetical order say.
然后按字典序排序

90
00:02:57,210 --> 00:02:57,980
It doesn't have to be sorted.
其实并不是一定要排序的啦

91
00:02:58,450 --> 00:02:59,910
But, you know, here's a, here's
你看

92
00:03:00,110 --> 00:03:02,080
my list of words, just count
这些是之前的单词 像“discount”

93
00:03:02,710 --> 00:03:03,950
and so on, until eventually
等等

94
00:03:04,160 --> 00:03:05,430
I'll get down to now, and so
还有单词"now" 等等

95
00:03:06,080 --> 00:03:07,230
on and given a piece
看看这个例子

96
00:03:07,350 --> 00:03:08,540
of e-mail like that shown on the
右边的这封邮件

97
00:03:08,610 --> 00:03:09,640
right, I'm going to
我准备

98
00:03:09,770 --> 00:03:11,400
check and see whether or
检查一下这些词汇

99
00:03:11,450 --> 00:03:12,560
not each of these words
看它们是否

100
00:03:13,030 --> 00:03:14,560
appears in the e-mail and then
出现在这封邮件中

101
00:03:14,810 --> 00:03:16,400
I'm going to define a feature
我用一个

102
00:03:16,580 --> 00:03:19,130
vector x where in
特征向量x

103
00:03:19,260 --> 00:03:20,260
this piece of an email on
表示右边的这封邮件

104
00:03:20,340 --> 00:03:21,520
the right, my name doesn't
我的名字没有出现

105
00:03:21,930 --> 00:03:23,210
appear so I'm gonna put a zero there.
因此这里是0

106
00:03:24,070 --> 00:03:25,410
The word "by" does appear,
单词"buy(购买)"出现了

107
00:03:26,790 --> 00:03:27,690
so I'm gonna put a one there
所以这里是1

108
00:03:28,090 --> 00:03:29,450
and I'm just gonna put one's or zeroes.
注意在向量里面只有1或0 表示有没有出现

109
00:03:30,170 --> 00:03:31,550
I'm gonna put a
所以尽管"buy"出现了两次

110
00:03:31,730 --> 00:03:33,950
one even though the word "by" occurs twice.
这里仍然只是1

111
00:03:34,600 --> 00:03:36,490
I'm not gonna recount how many times the word occurs.
注意我不会去统计每个词出现的次数

112
00:03:37,590 --> 00:03:40,280
The word "due" appears, I put a one there.
单词"deal"也出现了 所以这里也是1

113
00:03:40,900 --> 00:03:42,450
The word "discount" doesn't appear, at
单词"discount"并没有出现

114
00:03:42,620 --> 00:03:43,680
least not in this this little
至少在这封邮件里是这样

115
00:03:44,520 --> 00:03:46,140
short email, and so on.
以此类推

116
00:03:46,810 --> 00:03:48,740
The word "now" does appear and so on.
单词"now"出现了

117
00:03:48,870 --> 00:03:50,250
So I put ones and zeroes
所以我在特征向量中

118
00:03:50,560 --> 00:03:52,560
in this feature vector depending on
依据对应的单词是否出现

119
00:03:52,720 --> 00:03:54,230
whether or not a particular word appears.
填上0和1

120
00:03:55,060 --> 00:03:56,740
And in this example my
在这个例子中

121
00:03:56,870 --> 00:03:58,850
feature vector would have
因为我选择了100个单词

122
00:03:59,110 --> 00:04:00,920
to mention one hundred,
用于表示是否可能为垃圾邮件

123
00:04:02,310 --> 00:04:03,960
if I have a hundred,
所以

124
00:04:04,310 --> 00:04:05,460
if if I chose a hundred
这个特征向量x

125
00:04:05,650 --> 00:04:06,850
words to use for
的维度是100

126
00:04:07,010 --> 00:04:08,980
this representation and each
并且

127
00:04:09,240 --> 00:04:13,060
of my features Xj will
如果这个特定的单词

128
00:04:13,300 --> 00:04:15,150
basically be 1 if
即单词 j 出现在

129
00:04:16,360 --> 00:04:17,410
you have a particular word that,
这封邮件中

130
00:04:17,490 --> 00:04:18,930
we'll call this word j, appears
那么每一个特征变量

131
00:04:19,420 --> 00:04:20,940
in the email and Xj
Xj 的值为1

132
00:04:22,400 --> 00:04:23,910
would be zero otherwise.
反之 Xj为0

133
00:04:25,700 --> 00:04:25,700
Okay.
好的

134
00:04:25,900 --> 00:04:27,440
So that gives me
这样我们就可以使用特征向量

135
00:04:27,600 --> 00:04:30,220
a feature representation of a piece of email.
来表示这封邮件

136
00:04:30,920 --> 00:04:32,060
By the way, even though I've
顺便说一句

137
00:04:32,200 --> 00:04:34,260
described this process as manually
虽然我所描述的这个过程是我自己

138
00:04:34,920 --> 00:04:36,790
picking a hundred words, in
选取的100个单词

139
00:04:36,950 --> 00:04:38,510
practice what's most commonly
但是在实际工作中 最普遍的做法是

140
00:04:38,940 --> 00:04:40,140
done is to look through
遍历整个训练集

141
00:04:40,400 --> 00:04:42,710
a training set, and in
然后

142
00:04:42,800 --> 00:04:43,980
the training set depict the
在训练集中

143
00:04:44,050 --> 00:04:45,690
most frequently occurring n words
选出出现次数最多的n个单词

144
00:04:46,080 --> 00:04:47,290
where n is usually between ten
n一般介于10,000和50,000之间

145
00:04:47,450 --> 00:04:49,310
thousand and fifty thousand, and use
然后把这些单词

146
00:04:49,550 --> 00:04:50,810
those as your features.
作为你要用的特征

147
00:04:51,630 --> 00:04:52,910
So rather than manually picking a
因此不同于手动选取

148
00:04:53,090 --> 00:04:54,220
hundred words, here you look
我们只用遍历

149
00:04:54,390 --> 00:04:56,030
through the training examples and
训练样本

150
00:04:56,130 --> 00:04:57,570
pick the most frequently occurring words
然后选出出现频率最高的词语

151
00:04:57,930 --> 00:04:58,860
like ten thousand to fifty thousand
差不多是10,000到50,000个单词

152
00:04:59,260 --> 00:05:00,680
words, and those form the
这些单词会构成特征

153
00:05:00,820 --> 00:05:01,550
features that you are going
这样你就可以用它们

154
00:05:01,640 --> 00:05:04,320
to use to represent your email for spam classification.
来做垃圾邮件分类

155
00:05:05,450 --> 00:05:06,850
Now, if you're building a
如果你正在构造一个垃圾邮件分类器

156
00:05:06,910 --> 00:05:09,020
spam classifier one question
你应该会面对这样一个问题

157
00:05:09,570 --> 00:05:11,260
that you may face is, what's
那就是

158
00:05:11,500 --> 00:05:12,580
the best use of your time
如何在有限的时间和精力下

159
00:05:13,230 --> 00:05:14,820
in order to make your
改进你的方法

160
00:05:14,980 --> 00:05:17,510
spam classifier have higher accuracy, you have lower error.
从而使得你的垃圾邮件分类器具有较高的准确度

161
00:05:18,910 --> 00:05:21,350
One natural inclination is going to collect lots of data.
从直觉上讲 是要收集大量的数据

162
00:05:21,780 --> 00:05:21,780
Right?
对吧？

163
00:05:22,030 --> 00:05:23,120
And in fact there's this tendency
事实上确实好多人这么做

164
00:05:23,700 --> 00:05:24,670
to think that, well the
很多人认为

165
00:05:24,740 --> 00:05:26,590
more data we have the better the algorithm will do.
收集越多的数据 算法就会表现的越好

166
00:05:27,560 --> 00:05:28,850
And in fact, in the email
事实上

167
00:05:29,100 --> 00:05:30,500
spam domain, there are actually
就垃圾邮件分类而言

168
00:05:31,310 --> 00:05:32,840
pretty serious projects called Honey
有一个叫做"Honey Pot"的项目

169
00:05:33,180 --> 00:05:35,310
Pot Projects, which create fake
它可以建立一个

170
00:05:35,710 --> 00:05:37,090
email addresses and try to
假的邮箱地址

171
00:05:37,200 --> 00:05:38,910
get these fake email addresses into
故意将这些地址

172
00:05:39,140 --> 00:05:40,710
the hands of spammers and use
泄露给发垃圾邮件的人

173
00:05:40,910 --> 00:05:41,870
that to try to collect tons
这样就能收到大量的垃圾邮件

174
00:05:42,140 --> 00:05:43,440
of spam email, and therefore
你看 这样的话

175
00:05:44,120 --> 00:05:46,120
you know, get a lot of spam data to train learning algorithms.
我们就能得到非常多的垃圾邮件来训练学习算法

176
00:05:47,060 --> 00:05:48,760
But we've already seen in the
但是

177
00:05:49,150 --> 00:05:50,630
previous sets of videos
在前面的课程中我们知道

178
00:05:50,650 --> 00:05:53,340
that getting lots of data will often help, but not all the time.
大量的数据可能会有帮助 也可能没有

179
00:05:54,600 --> 00:05:55,810
But for most machine learning problems,
对于大部分的机器学习问题

180
00:05:56,430 --> 00:05:57,280
there are a lot of other things
还有很多办法

181
00:05:57,620 --> 00:05:59,780
you could usually imagine doing to improve performance.
用来提升机器学习的效果

182
00:06:00,970 --> 00:06:02,130
For spam, one thing you
比如对于垃圾邮件而言

183
00:06:02,230 --> 00:06:03,420
might think of is to develop
也许你会想到

184
00:06:03,960 --> 00:06:05,620
more sophisticated features on the
用更复杂的特征变量

185
00:06:05,820 --> 00:06:08,070
email, maybe based on the email routing information.
像是邮件的路径信息

186
00:06:09,850 --> 00:06:11,920
And this would be information contained in the email header.
这种信息通常会出现在邮件的标题中

187
00:06:13,130 --> 00:06:14,820
So, when spammers send email,
因此 垃圾邮件发送方在发送垃圾邮件时

188
00:06:15,250 --> 00:06:16,420
very often they will try
他们总会试图

189
00:06:16,690 --> 00:06:18,110
to obscure the origins of
让这个邮件的来源变得模糊一些

190
00:06:18,340 --> 00:06:20,260
the email, and maybe
或者是

191
00:06:20,470 --> 00:06:21,880
use fake email headers.
用假的邮件标题

192
00:06:22,900 --> 00:06:24,060
Or send email through very
或者通过不常见的服务器

193
00:06:24,410 --> 00:06:26,360
unusual sets of computer service.
来发送邮件

194
00:06:27,060 --> 00:06:29,880
Through very unusual routes, in order to get the spam to you.
用不常见的路由 他们就能给你发送垃圾邮件

195
00:06:30,490 --> 00:06:33,690
And some of this information will be reflected in the email header.
而且这些信息也有可能包含在邮件标题部分

196
00:06:35,000 --> 00:06:36,600
And so one can imagine,
因此可以想到

197
00:06:38,070 --> 00:06:39,300
looking at the email headers and
我们可以通过邮件的标题部分

198
00:06:39,410 --> 00:06:41,060
trying to develop more sophisticated features
来构造更加复杂的特征

199
00:06:41,510 --> 00:06:42,760
to capture this sort of
来获得一系列的邮件路由信息

200
00:06:43,010 --> 00:06:45,770
email routing information to identify if something is spam.
进而判定这是否是一封垃圾邮件

201
00:06:46,650 --> 00:06:47,890
Something else you might consider doing
你还可能会想到别的方法

202
00:06:48,380 --> 00:06:49,300
is to look at the
比如

203
00:06:49,640 --> 00:06:50,860
email message body, that is
从邮件的正文出发

204
00:06:51,100 --> 00:06:54,350
the email text, and try to develop more sophisticated features.
寻找一些复杂点的特征

205
00:06:55,320 --> 00:06:56,310
For example, should the word
例如

206
00:06:56,500 --> 00:06:57,560
'discount' and the word
单词"discount"

207
00:06:57,690 --> 00:06:59,340
'discounts' be treated as
是否和单词"discounts"是一样的

208
00:06:59,550 --> 00:07:01,810
the same words or should
又比如

209
00:07:02,240 --> 00:07:04,120
we have treat the words 'deal' and 'dealer' as the same word?
单词"deal(交易)"和"dealer(交易商)"是否也应视为等同

210
00:07:04,380 --> 00:07:05,610
Maybe even though one is
甚至 像这个例子中

211
00:07:06,130 --> 00:07:08,020
lower case and one in capitalized in this example.
有的单词小写有的大写

212
00:07:08,740 --> 00:07:10,530
Or do we want more complex features about punctuation because maybe spam
或者我们是否应该用标点符号来构造复杂的特征变量

213
00:07:12,740 --> 00:07:14,110
is using exclamation marks a lot more.
因为垃圾邮件可能会更多的使用感叹号

214
00:07:14,450 --> 00:07:14,730
I don't know.
这些都不一定

215
00:07:15,580 --> 00:07:16,850
And along the same lines, maybe
同样的

216
00:07:17,170 --> 00:07:18,560
we also want to develop more
我们也可能构造

217
00:07:18,750 --> 00:07:20,380
sophisticated algorithms to detect
更加复杂的算法来检测

218
00:07:21,120 --> 00:07:22,700
and maybe to correct to deliberate misspellings,
或者纠正那些故意的拼写错误

219
00:07:23,360 --> 00:07:24,700
like mortgage, medicine, watches.
例如 "m0rtgage" "med1cine" "w4tches"

220
00:07:25,700 --> 00:07:26,890
Because spammers actually do this,
因为垃圾邮件发送方确实这么做了

221
00:07:27,150 --> 00:07:28,400
because if you have watches
因为如果你将4放到"w4tches"中

222
00:07:29,420 --> 00:07:31,060
with a 4 in there then well,
那么

223
00:07:31,450 --> 00:07:32,720
with the simple technique that we
用我们之前提到的

224
00:07:32,840 --> 00:07:34,760
talked about just now, the spam
简单的方法

225
00:07:35,090 --> 00:07:36,280
classifier might not equate
垃圾邮件分类器不会把"w4tches"

226
00:07:36,800 --> 00:07:38,170
this as the same thing as the
和"watches"

227
00:07:38,230 --> 00:07:40,260
word "watches," and so it
看成一样的

228
00:07:40,390 --> 00:07:41,430
may have a harder time realizing
这样我们就很难区分这些

229
00:07:42,000 --> 00:07:43,930
that something is spam with these deliberate misspellings.
故意拼错的垃圾邮件

230
00:07:44,830 --> 00:07:45,940
And this is why spammers do it.
发垃圾邮件的也很机智 他们这么做就逃避了一些过滤

231
00:07:48,230 --> 00:07:49,280
While working on a machine learning
当我们使用机器学习时

232
00:07:49,630 --> 00:07:51,370
problem, very often you
总是可以“头脑风暴”一下

233
00:07:51,480 --> 00:07:54,690
can brainstorm lists of different things to try, like these.
想出一堆方法来试试 就像这样

234
00:07:55,170 --> 00:07:56,560
By the way, I've actually
顺带一提

235
00:07:56,790 --> 00:07:58,480
worked on the spam
我有一段时间

236
00:07:58,900 --> 00:08:00,000
problem myself for a while.
研究过垃圾邮件分类的问题

237
00:08:00,650 --> 00:08:01,610
And I actually spent quite some time on it.
实际上我花了很多时间来研究这个

238
00:08:01,770 --> 00:08:03,040
And even though I kind
尽管我能够理解

239
00:08:03,360 --> 00:08:04,350
of understand the spam problem,
垃圾邮件分类的问题

240
00:08:04,820 --> 00:08:05,820
I actually know a bit about it,
我确实懂一些这方面的东西

241
00:08:06,470 --> 00:08:07,380
I would actually have a very
但是

242
00:08:07,600 --> 00:08:09,160
hard time telling you of
我还是很难告诉你

243
00:08:09,290 --> 00:08:10,790
these four options which is
这四种方法中

244
00:08:10,980 --> 00:08:12,190
the best use of your time
你最该去使用哪一种

245
00:08:12,670 --> 00:08:14,180
so what happens, frankly what
事实上 坦白地说

246
00:08:14,320 --> 00:08:15,790
happens far too often is
最常见的情况是

247
00:08:16,040 --> 00:08:17,240
that a research group or
一个研究小组

248
00:08:17,350 --> 00:08:20,330
product group will randomly fixate on one of these options.
可能会随机确定其中的一个方法

249
00:08:21,290 --> 00:08:22,870
And sometimes that turns
但是有时候

250
00:08:23,250 --> 00:08:24,350
out not to be the most
这种方法

251
00:08:24,580 --> 00:08:25,610
fruitful way to spend your
并不是最有成效的

252
00:08:25,740 --> 00:08:27,700
time depending, you know, on which
你知道

253
00:08:27,900 --> 00:08:30,400
of these options someone ends up randomly fixating on.
你只是随机选择了其中的一种方法

254
00:08:31,350 --> 00:08:32,670
By the way, in fact, if
实际上

255
00:08:32,800 --> 00:08:33,780
you even get to the stage
当你需要通过

256
00:08:34,150 --> 00:08:35,710
where you brainstorm a list
头脑风暴来想出

257
00:08:35,900 --> 00:08:37,100
of different options to try, you're
不同方法来尝试去提高精度的时候

258
00:08:37,250 --> 00:08:38,740
probably already ahead of the curve.
你可能已经超越了很多人了

259
00:08:39,390 --> 00:08:41,190
Sadly, what most people do is
令人难过的是 大部分人

260
00:08:41,420 --> 00:08:42,160
instead of trying to list
他们并不尝试着

261
00:08:42,230 --> 00:08:43,010
out the options of things
列出可能的方法

262
00:08:43,240 --> 00:08:44,510
you might try, what far too
他们做的

263
00:08:44,810 --> 00:08:46,100
many people do is wake up
只是

264
00:08:46,210 --> 00:08:47,380
one morning and, for some
某天早上醒来

265
00:08:47,580 --> 00:08:48,850
reason, just, you know, have a weird
因为某些原因

266
00:08:49,110 --> 00:08:50,440
gut feeling that, "Oh let's
有了一个突发奇想

267
00:08:51,290 --> 00:08:52,670
have a huge honeypot project
"让我们来试试 用Honey Pot项目

268
00:08:53,190 --> 00:08:54,570
to go and collect tons more data"
收集大量的数据吧"

269
00:08:55,320 --> 00:08:56,860
and for whatever strange reason just
不管出于什么奇怪的原因

270
00:08:57,570 --> 00:08:58,540
sort of wake up one morning and randomly
早上的灵机一动

271
00:08:59,050 --> 00:09:00,330
fixate on one thing and just
还是随机选一个

272
00:09:00,540 --> 00:09:02,340
work on that for six months.
然后干上大半年

273
00:09:03,520 --> 00:09:04,170
But I think we can do better.
但是我觉得我们有更好的方法

274
00:09:04,760 --> 00:09:06,130
And in particular what I'd
是的

275
00:09:06,270 --> 00:09:07,130
like to do in the next
我们将在随后的课程中

276
00:09:07,310 --> 00:09:08,410
video is tell you about
讲到这个

277
00:09:08,680 --> 00:09:09,890
the concept of error analysis
那就是误差分析

278
00:09:11,160 --> 00:09:12,530
and talk about the way
我会告诉你

279
00:09:13,270 --> 00:09:15,150
where you can try
怎样用一个

280
00:09:15,360 --> 00:09:16,830
to have a more systematic way
更加系统性的方法

281
00:09:17,360 --> 00:09:18,640
to choose amongst the options
从一堆不同的方法中

282
00:09:18,960 --> 00:09:19,950
of the many different things you
选取合适的那一个

283
00:09:20,010 --> 00:09:21,730
might work, and therefore be
因此

284
00:09:21,860 --> 00:09:23,430
more likely to select what
你更有可能选择

285
00:09:23,640 --> 00:09:24,820
is actually a good way
一个真正的好方法

286
00:09:25,070 --> 00:09:26,070
to spend your time, you know
能让你花上几天几周 甚至是几个月

287
00:09:26,200 --> 00:09:28,920
for the next few weeks, or next few days or the next few months.
去进行深入的研究

