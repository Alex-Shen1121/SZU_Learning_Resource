{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基于用户声誉的鲁棒协同推荐算法\n",
      "基于覆盖随机游走算法的服务质量预测\n",
      "基于SOM神经网络的服务质量预测\n",
      "异质信息网络中元路径感知的评分协同过滤\n",
      "基于位置服务的分布式差分隐私推荐方法研究\n",
      "基于时间访问轨迹的文件的智能推荐\n",
      "协同过滤推荐系统中的用户博弈\n",
      "基于网络表示学习的个性化商品推荐\n",
      "人机协作的用户故事场景提取与迭代演进\n",
      "基于图嵌入的软件项目源代码检索方法\n"
     ]
    }
   ],
   "source": [
    "# 读取文档，并按行分隔\n",
    "doc = open('HW3.txt', 'r', encoding='gbk').read().splitlines()\n",
    "for sentence in doc[:10]:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/m0/dsy0kdw13rb2g65q1x0bqn_00000gn/T/jieba.cache\n",
      "Loading model cost 0.337 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(token) = 6190\n",
      "len(term) = 1128\n"
     ]
    }
   ],
   "source": [
    "# 添加自定义词库（可选）\n",
    "for path in os.listdir('dictionary'):\n",
    "    jieba.load_userdict('dictionary/' + path)\n",
    "\n",
    "# 计算token，term数量\n",
    "# token使用list存储，term使用set存储(可去重)\n",
    "token, term = list(), set()\n",
    "for sentence in doc:\n",
    "    # 利用jieba进行分词 返回分词后的结果\n",
    "    seg_list = list(jieba.cut(sentence, cut_all=False))\n",
    "    # print('--------------------------------------------------------------')\n",
    "    # print('sentence:', sentence)\n",
    "    # print('seg_list:', seg_list)\n",
    "    token.extend(seg_list)\n",
    "    term.update(seg_list)\n",
    "print('len(token) =', len(token))\n",
    "print('len(term) =', len(term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "hashtable = {}\n",
    "for index, sentence in enumerate(doc):\n",
    "    # 利用jieba进行分词 返回分词后的结果\n",
    "    # 使用精确模式\n",
    "    for word in jieba.cut(sentence, cut_all=False):\n",
    "        if word in hashtable:\n",
    "            hashtable[word].append(index+1)\n",
    "            hashtable[word][0] += 1\n",
    "        else:\n",
    "            hashtable[word] = [1, index+1]\n",
    "            \n",
    "hashtable = dict(\n",
    "    sorted(hashtable.items(), key=lambda kv: (kv[1][0], kv[0]), reverse=True))\n",
    "\n",
    "# print(hashtable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>doc.freq</th>\n",
       "      <th>postings list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>的</td>\n",
       "      <td>557</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 14,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>基于</td>\n",
       "      <td>340</td>\n",
       "      <td>[1, 2, 3, 5, 6, 8, 10, 12, 14, 15, 16, 17, 18,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>推荐</td>\n",
       "      <td>255</td>\n",
       "      <td>[1, 5, 6, 7, 8, 14, 18, 20, 22, 23, 24, 25, 26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>学习</td>\n",
       "      <td>199</td>\n",
       "      <td>[8, 29, 53, 54, 62, 137, 142, 151, 166, 167, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>研究</td>\n",
       "      <td>196</td>\n",
       "      <td>[5, 13, 20, 24, 29, 31, 32, 35, 40, 41, 42, 43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>迁移</td>\n",
       "      <td>190</td>\n",
       "      <td>[25, 246, 288, 364, 365, 366, 367, 368, 369, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>方法</td>\n",
       "      <td>167</td>\n",
       "      <td>[5, 10, 14, 19, 24, 26, 27, 33, 44, 64, 66, 67...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>算法</td>\n",
       "      <td>103</td>\n",
       "      <td>[1, 2, 17, 18, 20, 21, 22, 23, 25, 34, 54, 59,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>模型</td>\n",
       "      <td>93</td>\n",
       "      <td>[18, 22, 23, 37, 45, 48, 50, 51, 52, 53, 57, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>和</td>\n",
       "      <td>88</td>\n",
       "      <td>[22, 25, 27, 34, 57, 80, 100, 105, 106, 107, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>一种</td>\n",
       "      <td>80</td>\n",
       "      <td>[14, 33, 34, 44, 54, 59, 60, 67, 68, 72, 83, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>与</td>\n",
       "      <td>71</td>\n",
       "      <td>[9, 11, 60, 65, 71, 88, 103, 134, 158, 171, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>协同</td>\n",
       "      <td>65</td>\n",
       "      <td>[1, 4, 7, 13, 14, 17, 18, 19, 21, 22, 54, 79, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>网络</td>\n",
       "      <td>63</td>\n",
       "      <td>[8, 13, 28, 30, 35, 47, 77, 79, 84, 87, 100, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>深度</td>\n",
       "      <td>57</td>\n",
       "      <td>[26, 28, 29, 80, 137, 295, 326, 359, 387, 393,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>过滤</td>\n",
       "      <td>50</td>\n",
       "      <td>[4, 7, 13, 14, 17, 18, 19, 22, 82, 84, 85, 90,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>中</td>\n",
       "      <td>46</td>\n",
       "      <td>[4, 7, 59, 86, 129, 150, 175, 194, 195, 259, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>系统</td>\n",
       "      <td>45</td>\n",
       "      <td>[7, 29, 30, 32, 35, 36, 38, 41, 42, 43, 49, 55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>预测</td>\n",
       "      <td>44</td>\n",
       "      <td>[2, 3, 11, 61, 64, 90, 113, 128, 134, 214, 228...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>用户</td>\n",
       "      <td>41</td>\n",
       "      <td>[1, 7, 9, 11, 37, 43, 46, 56, 57, 74, 77, 92, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   term doc.freq                                      postings list\n",
       "0     的      557  [1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 14,...\n",
       "1    基于      340  [1, 2, 3, 5, 6, 8, 10, 12, 14, 15, 16, 17, 18,...\n",
       "2    推荐      255  [1, 5, 6, 7, 8, 14, 18, 20, 22, 23, 24, 25, 26...\n",
       "3    学习      199  [8, 29, 53, 54, 62, 137, 142, 151, 166, 167, 1...\n",
       "4    研究      196  [5, 13, 20, 24, 29, 31, 32, 35, 40, 41, 42, 43...\n",
       "5    迁移      190  [25, 246, 288, 364, 365, 366, 367, 368, 369, 3...\n",
       "6    方法      167  [5, 10, 14, 19, 24, 26, 27, 33, 44, 64, 66, 67...\n",
       "7    算法      103  [1, 2, 17, 18, 20, 21, 22, 23, 25, 34, 54, 59,...\n",
       "8    模型       93  [18, 22, 23, 37, 45, 48, 50, 51, 52, 53, 57, 5...\n",
       "9     和       88  [22, 25, 27, 34, 57, 80, 100, 105, 106, 107, 1...\n",
       "10   一种       80  [14, 33, 34, 44, 54, 59, 60, 67, 68, 72, 83, 8...\n",
       "11    与       71  [9, 11, 60, 65, 71, 88, 103, 134, 158, 171, 18...\n",
       "12   协同       65  [1, 4, 7, 13, 14, 17, 18, 19, 21, 22, 54, 79, ...\n",
       "13   网络       63  [8, 13, 28, 30, 35, 47, 77, 79, 84, 87, 100, 1...\n",
       "14   深度       57  [26, 28, 29, 80, 137, 295, 326, 359, 387, 393,...\n",
       "15   过滤       50  [4, 7, 13, 14, 17, 18, 19, 22, 82, 84, 85, 90,...\n",
       "16    中       46  [4, 7, 59, 86, 129, 150, 175, 194, 195, 259, 2...\n",
       "17   系统       45  [7, 29, 30, 32, 35, 36, 38, 41, 42, 43, 49, 55...\n",
       "18   预测       44  [2, 3, 11, 61, 64, 90, 113, 128, 134, 214, 228...\n",
       "19   用户       41  [1, 7, 9, 11, 37, 43, 46, 56, 57, 74, 77, 92, ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inverted_index = pd.DataFrame(columns=['term', 'doc.freq', 'postings list'])\n",
    "for term in hashtable:\n",
    "    inverted_index = inverted_index.append(\n",
    "        {'term': term, 'doc.freq': hashtable[term][0], 'postings list': hashtable[term][1:]}, ignore_index=True)\n",
    "display(inverted_index[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>doc.freq</th>\n",
       "      <th>postings list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>迁移</td>\n",
       "      <td>190</td>\n",
       "      <td>[25, 246, 288, 364, 365, 366, 367, 368, 369, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>迁移学习</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>推荐</td>\n",
       "      <td>255</td>\n",
       "      <td>[1, 5, 6, 7, 8, 14, 18, 20, 22, 23, 24, 25, 26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>深度学习</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>隐私</td>\n",
       "      <td>11</td>\n",
       "      <td>[5, 14, 93, 96, 128, 140, 149, 255, 319, 350, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>跨领域</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>跨域</td>\n",
       "      <td>27</td>\n",
       "      <td>[216, 369, 370, 371, 377, 387, 398, 406, 407, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   term doc.freq                                      postings list\n",
       "0    迁移      190  [25, 246, 288, 364, 365, 366, 367, 368, 369, 3...\n",
       "1  迁移学习        0                                                 []\n",
       "2    推荐      255  [1, 5, 6, 7, 8, 14, 18, 20, 22, 23, 24, 25, 26...\n",
       "3  深度学习        0                                                 []\n",
       "4    隐私       11  [5, 14, 93, 96, 128, 140, 149, 255, 319, 350, ...\n",
       "5   跨领域        0                                                 []\n",
       "6    跨域       27  [216, 369, 370, 371, 377, 387, 398, 406, 407, ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_index = pd.DataFrame(columns=['term', 'doc.freq', 'postings list'])\n",
    "query = ['迁移', '迁移学习', '推荐', '深度学习', '隐私', '跨领域', '跨域']\n",
    "for term in query:\n",
    "    if term in hashtable:\n",
    "        query_index = query_index.append(\n",
    "            {'term': term, 'doc.freq': hashtable[term][0], 'postings list': hashtable[term][1:]}, ignore_index=True)\n",
    "    else:\n",
    "        query_index = query_index.append(\n",
    "            {'term': term, 'doc.freq': 0, 'postings list': []}, ignore_index=True)\n",
    "display(query_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # encoding=utf-8\n",
    "# import jieba\n",
    "\n",
    "# # jieba.enable_paddle()# 启动paddle模式。 0.40版之后开始支持，早期版本不支持\n",
    "# strs=[\"我来到北京清华大学\",\"乒乓球拍卖完了\",\"中国科学技术大学\"]\n",
    "# for str in strs:\n",
    "#     seg_list = jieba.cut(str,use_paddle=True) # 使用paddle模式\n",
    "#     print(\"Paddle Mode: \" + '/'.join(list(seg_list)))\n",
    "\n",
    "# seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "# print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n",
    "# seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "# print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式\n",
    "\n",
    "# seg_list = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式\n",
    "# print(\", \".join(seg_list))\n",
    "\n",
    "# seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "# print(\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import fool\n",
    "\n",
    "# text = \"一个傻子在北京\"\n",
    "# print(fool.cut(text))\n",
    "# # ['一个', '傻子', '在', '北京']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from LAC import LAC\n",
    "\n",
    "# # 装载分词模型\n",
    "# lac = LAC(mode='seg')\n",
    "\n",
    "# # 单个样本输入，输入为Unicode编码的字符串\n",
    "# text = u\"LAC是个优秀的分词工具\"\n",
    "# seg_result = lac.run(text)\n",
    "\n",
    "# # 批量样本输入, 输入为多个句子组成的list，平均速率会更快\n",
    "# texts = [u\"LAC是个优秀的分词工具\", u\"百度是一家高科技公司\"]\n",
    "# seg_result = lac.run(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'jieba_dict.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m0/dsy0kdw13rb2g65q1x0bqn_00000gn/T/ipykernel_13477/1171080193.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mjieba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_userdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jieba_dict.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/jieba/__init__.py\u001b[0m in \u001b[0;36mload_userdict\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolve_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'jieba_dict.txt'"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    jieba.load_userdict('jieba_dict.txt')\n",
    "    document = dict()\n",
    "    i = 1\n",
    "    with open(\"HW3.txt\", \"r\", encoding='gbk') as f:  # 打开文件,必须用txt的编码格式，否则会报错\n",
    "        for line in f.readlines():\n",
    "            line = line.strip('。')  # 删去标点符号\n",
    "            line = line.strip('，')\n",
    "            line = line.strip('\\n')\n",
    "            line = line.strip('——')\n",
    "            document[i] = jieba.lcut(line, cut_all=True)  # 规格化为小写\n",
    "            i = i + 1\n",
    "    # print(data)\n",
    "    all_words = []\n",
    "    for i in document.values():\n",
    "        all_words.extend(i)\n",
    "    words = set(all_words)\n",
    "    words.remove('')\n",
    "    # print(set_all_words)\n",
    "\n",
    "    invert_index = dict()\n",
    "    for b in words:\n",
    "        temp = []\n",
    "        for j in document.keys():\n",
    "            field = document[j]\n",
    "            if b in field:  # 查找单词在文章里面是否存在\n",
    "                temp.append(j)\n",
    "        invert_index[b] = temp\n",
    "    # print(invert_index)\n",
    "    print('迁移: '+str(invert_index['迁移']))\n",
    "    print('迁移学习: '+str(invert_index['迁移学习']))\n",
    "    print('推荐: '+str(invert_index['推荐']))\n",
    "    print('深度学习: '+str(invert_index['深度学习']))\n",
    "    print('隐私: '+str(invert_index['隐私']))\n",
    "    # print('跨领域: ' + str(invert_index['跨领域']))\n",
    "    print('跨域: ' + str(invert_index['跨域']))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b38f256b5e5cfcb08c8fab1bb2c0ed1d264b1b0baf1af9aa926f047321c09a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
